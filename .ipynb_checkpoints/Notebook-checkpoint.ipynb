{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "240d3437-6d64-4ded-b533-8287bba956fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional, Union\n",
    "import numpy as np\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2\n",
    "from onnxruntime import GraphOptimizationLevel, InferenceSession, SessionOptions\n",
    "\n",
    "import chardet\n",
    "import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "\n",
    "InputType = Union[str, np.ndarray, bytes, Path]\n",
    "\n",
    "class EncoderDecoder:\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_path: Union[Path, str],\n",
    "        decoder_path: Union[Path, str],\n",
    "        bos_token: int,\n",
    "        eos_token: int,\n",
    "        max_seq_len: int,\n",
    "    ):\n",
    "        self.bos_token = bos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "        self.encoder = OrtInferSession(encoder_path)\n",
    "        self.decoder = Decoder(decoder_path)\n",
    "\n",
    "    def __call__(self, x: np.ndarray, temperature: float = 0.25):\n",
    "        ort_input_data = np.array([self.bos_token] * len(x))[:, None]\n",
    "        context = self.encoder([x])[0]\n",
    "        output = self.decoder(\n",
    "            ort_input_data,\n",
    "            self.max_seq_len,\n",
    "            eos_token=self.eos_token,\n",
    "            context=context,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "class Decoder:\n",
    "    def __init__(self, decoder_path: Union[Path, str]):\n",
    "        self.max_seq_len = 512\n",
    "        self.session = OrtInferSession(decoder_path)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        start_tokens,\n",
    "        seq_len=256,\n",
    "        eos_token=None,\n",
    "        temperature=1.0,\n",
    "        filter_thres=0.9,\n",
    "        context=None,\n",
    "    ):\n",
    "        num_dims = len(start_tokens.shape)\n",
    "\n",
    "        b, t = start_tokens.shape\n",
    "\n",
    "        out = start_tokens\n",
    "        mask = np.full_like(start_tokens, True, dtype=bool)\n",
    "\n",
    "        for _ in range(seq_len):\n",
    "            x = out[:, -self.max_seq_len :]\n",
    "            mask = mask[:, -self.max_seq_len :]\n",
    "\n",
    "            ort_outs = self.session([x.astype(np.int64), mask, context])[0]\n",
    "            np_preds = ort_outs\n",
    "            np_logits = np_preds[:, -1, :]\n",
    "\n",
    "            np_filtered_logits = self.npp_top_k(np_logits, thres=filter_thres)\n",
    "            np_probs = self.softmax(np_filtered_logits / temperature, axis=-1)\n",
    "\n",
    "            sample = self.multinomial(np_probs.squeeze(), 1)[None, ...]\n",
    "\n",
    "            out = np.concatenate([out, sample], axis=-1)\n",
    "            mask = np.pad(mask, [(0, 0), (0, 1)], \"constant\", constant_values=True)\n",
    "\n",
    "            if (\n",
    "                eos_token is not None\n",
    "                and (np.cumsum(out == eos_token, axis=1)[:, -1] >= 1).all()\n",
    "            ):\n",
    "                break\n",
    "\n",
    "        out = out[:, t:]\n",
    "        if num_dims == 1:\n",
    "            out = out.squeeze(0)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x, axis=None) -> float:\n",
    "        def logsumexp(a, axis=None, b=None, keepdims=False):\n",
    "            a_max = np.amax(a, axis=axis, keepdims=True)\n",
    "\n",
    "            if a_max.ndim > 0:\n",
    "                a_max[~np.isfinite(a_max)] = 0\n",
    "            elif not np.isfinite(a_max):\n",
    "                a_max = 0\n",
    "\n",
    "            tmp = np.exp(a - a_max)\n",
    "\n",
    "            # suppress warnings about log of zero\n",
    "            with np.errstate(divide=\"ignore\"):\n",
    "                s = np.sum(tmp, axis=axis, keepdims=keepdims)\n",
    "                out = np.log(s)\n",
    "\n",
    "            if not keepdims:\n",
    "                a_max = np.squeeze(a_max, axis=axis)\n",
    "            out += a_max\n",
    "            return out\n",
    "\n",
    "        return np.exp(x - logsumexp(x, axis=axis, keepdims=True))\n",
    "\n",
    "    def npp_top_k(self, logits, thres=0.9):\n",
    "        k = int((1 - thres) * logits.shape[-1])\n",
    "        val, ind = self.np_top_k(logits, k)\n",
    "        probs = np.full_like(logits, float(\"-inf\"))\n",
    "        np.put_along_axis(probs, ind, val, axis=1)\n",
    "        return probs\n",
    "\n",
    "    @staticmethod\n",
    "    def np_top_k(\n",
    "        a: np.ndarray, k: int, axis=-1, largest=True, sorted=True\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        if axis is None:\n",
    "            axis_size = a.size\n",
    "        else:\n",
    "            axis_size = a.shape[axis]\n",
    "\n",
    "        assert 1 <= k <= axis_size\n",
    "\n",
    "        a = np.asanyarray(a)\n",
    "        if largest:\n",
    "            index_array = np.argpartition(a, axis_size - k, axis=axis)\n",
    "            topk_indices = np.take(index_array, -np.arange(k) - 1, axis=axis)\n",
    "        else:\n",
    "            index_array = np.argpartition(a, k - 1, axis=axis)\n",
    "            topk_indices = np.take(index_array, np.arange(k), axis=axis)\n",
    "\n",
    "        topk_values = np.take_along_axis(a, topk_indices, axis=axis)\n",
    "        if sorted:\n",
    "            sorted_indices_in_topk = np.argsort(topk_values, axis=axis)\n",
    "            if largest:\n",
    "                sorted_indices_in_topk = np.flip(sorted_indices_in_topk, axis=axis)\n",
    "            sorted_topk_values = np.take_along_axis(\n",
    "                topk_values, sorted_indices_in_topk, axis=axis\n",
    "            )\n",
    "            sorted_topk_indices = np.take_along_axis(\n",
    "                topk_indices, sorted_indices_in_topk, axis=axis\n",
    "            )\n",
    "            return sorted_topk_values, sorted_topk_indices\n",
    "        return topk_values, topk_indices\n",
    "\n",
    "    @staticmethod\n",
    "    def multinomial(weights, num_samples, replacement=True):\n",
    "        weights = np.asarray(weights)\n",
    "        weights /= np.sum(weights)  # 确保权重之和为1\n",
    "        indices = np.arange(len(weights))\n",
    "        samples = np.random.choice(\n",
    "            indices, size=num_samples, replace=replacement, p=weights\n",
    "        )\n",
    "        return samples\n",
    "\n",
    "class LoadImage:\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img: InputType) -> np.ndarray:\n",
    "        if not isinstance(img, InputType.__args__):\n",
    "            raise LoadImageError(\n",
    "                f\"The img type {type(img)} does not in {InputType.__args__}\"\n",
    "            )\n",
    "\n",
    "        img = self.load_img(img)\n",
    "        img = self.convert_img(img)\n",
    "        return img\n",
    "\n",
    "    def load_img(self, img: InputType) -> np.ndarray:\n",
    "        if isinstance(img, (str, Path)):\n",
    "            self.verify_exist(img)\n",
    "            try:\n",
    "                img = np.array(Image.open(img))\n",
    "            except UnidentifiedImageError as e:\n",
    "                raise LoadImageError(f\"cannot identify image file {img}\") from e\n",
    "            return img\n",
    "\n",
    "        if isinstance(img, bytes):\n",
    "            img = np.array(Image.open(BytesIO(img)))\n",
    "            return img\n",
    "\n",
    "        if isinstance(img, np.ndarray):\n",
    "            return img\n",
    "\n",
    "        raise LoadImageError(f\"{type(img)} is not supported!\")\n",
    "\n",
    "    def convert_img(self, img: np.ndarray):\n",
    "        if img.ndim == 2:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        if img.ndim == 3:\n",
    "            channel = img.shape[2]\n",
    "            if channel == 1:\n",
    "                return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            if channel == 2:\n",
    "                return self.cvt_two_to_three(img)\n",
    "\n",
    "            if channel == 4:\n",
    "                return self.cvt_four_to_three(img)\n",
    "\n",
    "            if channel == 3:\n",
    "                return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            raise LoadImageError(\n",
    "                f\"The channel({channel}) of the img is not in [1, 2, 3, 4]\"\n",
    "            )\n",
    "\n",
    "        raise LoadImageError(f\"The ndim({img.ndim}) of the img is not in [2, 3]\")\n",
    "\n",
    "    @staticmethod\n",
    "    def cvt_four_to_three(img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"RGBA → BGR\"\"\"\n",
    "        r, g, b, a = cv2.split(img)\n",
    "        new_img = cv2.merge((b, g, r))\n",
    "\n",
    "        not_a = cv2.bitwise_not(a)\n",
    "        not_a = cv2.cvtColor(not_a, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        new_img = cv2.bitwise_and(new_img, new_img, mask=a)\n",
    "        new_img = cv2.add(new_img, not_a)\n",
    "        return new_img\n",
    "\n",
    "    @staticmethod\n",
    "    def cvt_two_to_three(img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"gray + alpha → BGR\"\"\"\n",
    "        img_gray = img[..., 0]\n",
    "        img_bgr = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        img_alpha = img[..., 1]\n",
    "        not_a = cv2.bitwise_not(img_alpha)\n",
    "        not_a = cv2.cvtColor(not_a, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        new_img = cv2.bitwise_and(img_bgr, img_bgr, mask=img_alpha)\n",
    "        new_img = cv2.add(new_img, not_a)\n",
    "        return new_img\n",
    "\n",
    "    @staticmethod\n",
    "    def verify_exist(file_path: Union[str, Path]):\n",
    "        if not Path(file_path).exists():\n",
    "            raise LoadImageError(f\"{file_path} does not exist.\")\n",
    "\n",
    "class LoadImageError(Exception):\n",
    "    pass\n",
    "\n",
    "class OrtInferSession:\n",
    "    def __init__(self, model_path: Union[str, Path], num_threads: int = -1):\n",
    "        self.verify_exist(model_path)\n",
    "\n",
    "        self.num_threads = num_threads\n",
    "        self._init_sess_opt()\n",
    "\n",
    "        cpu_ep = \"CPUExecutionProvider\"\n",
    "        cpu_provider_options = {\n",
    "            \"arena_extend_strategy\": \"kSameAsRequested\",\n",
    "        }\n",
    "        EP_list = [(cpu_ep, cpu_provider_options)]\n",
    "        try:\n",
    "            self.session = InferenceSession(\n",
    "                str(model_path), sess_options=self.sess_opt, providers=EP_list\n",
    "            )\n",
    "        except TypeError:\n",
    "            # compatible with onnxruntime 1.5.2\n",
    "            self.session = InferenceSession(str(model_path), sess_options=self.sess_opt)\n",
    "\n",
    "    def _init_sess_opt(self):\n",
    "        self.sess_opt = SessionOptions()\n",
    "        self.sess_opt.log_severity_level = 4\n",
    "        self.sess_opt.enable_cpu_mem_arena = False\n",
    "\n",
    "        if self.num_threads != -1:\n",
    "            self.sess_opt.intra_op_num_threads = self.num_threads\n",
    "\n",
    "        self.sess_opt.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "\n",
    "    def __call__(self, input_content: List[np.ndarray]) -> np.ndarray:\n",
    "        input_dict = dict(zip(self.get_input_names(), input_content))\n",
    "        try:\n",
    "            return self.session.run(None, input_dict)\n",
    "        except Exception as e:\n",
    "            error_info = traceback.format_exc()\n",
    "            raise ONNXRuntimeError(error_info) from e\n",
    "\n",
    "    def get_input_names(\n",
    "        self,\n",
    "    ):\n",
    "        return [v.name for v in self.session.get_inputs()]\n",
    "\n",
    "    def get_output_name(self, output_idx=0):\n",
    "        return self.session.get_outputs()[output_idx].name\n",
    "\n",
    "    def get_metadata(self):\n",
    "        meta_dict = self.session.get_modelmeta().custom_metadata_map\n",
    "        return meta_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def verify_exist(model_path: Union[Path, str]):\n",
    "        if not isinstance(model_path, Path):\n",
    "            model_path = Path(model_path)\n",
    "\n",
    "        if not model_path.exists():\n",
    "            raise FileNotFoundError(f\"{model_path} does not exist!\")\n",
    "\n",
    "        if not model_path.is_file():\n",
    "            raise FileExistsError(f\"{model_path} must be a file\")\n",
    "\n",
    "\n",
    "class ONNXRuntimeError(Exception):\n",
    "    pass\n",
    "\n",
    "class PreProcess:\n",
    "    def __init__(self, max_dims: List[int], min_dims: List[int]):\n",
    "        self.max_dims, self.min_dims = max_dims, min_dims\n",
    "        self.mean = np.array([0.7931, 0.7931, 0.7931]).astype(np.float32)\n",
    "        self.std = np.array([0.1738, 0.1738, 0.1738]).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def pad(img: Image.Image, divable: int = 32) -> Image.Image:\n",
    "        \"\"\"Pad an Image to the next full divisible value of `divable`. Also normalizes the image and invert if needed.\n",
    "\n",
    "        Args:\n",
    "            img (PIL.Image): input image\n",
    "            divable (int, optional): . Defaults to 32.\n",
    "\n",
    "        Returns:\n",
    "            PIL.Image\n",
    "        \"\"\"\n",
    "        threshold = 128\n",
    "        data = np.array(img.convert(\"LA\"))\n",
    "        if data[..., -1].var() == 0:\n",
    "            data = (data[..., 0]).astype(np.uint8)\n",
    "        else:\n",
    "            data = (255 - data[..., -1]).astype(np.uint8)\n",
    "\n",
    "        data = (data - data.min()) / (data.max() - data.min()) * 255\n",
    "        if data.mean() > threshold:\n",
    "            # To invert the text to white\n",
    "            gray = 255 * (data < threshold).astype(np.uint8)\n",
    "        else:\n",
    "            gray = 255 * (data > threshold).astype(np.uint8)\n",
    "            data = 255 - data\n",
    "\n",
    "        coords = cv2.findNonZero(gray)  # Find all non-zero points (text)\n",
    "        a, b, w, h = cv2.boundingRect(coords)  # Find minimum spanning bounding box\n",
    "        rect = data[b : b + h, a : a + w]\n",
    "        im = Image.fromarray(rect).convert(\"L\")\n",
    "        dims: List[Union[int, int]] = []\n",
    "        for x in [w, h]:\n",
    "            div, mod = divmod(x, divable)\n",
    "            dims.append(divable * (div + (1 if mod > 0 else 0)))\n",
    "\n",
    "        padded = Image.new(\"L\", tuple(dims), 255)\n",
    "        padded.paste(im, (0, 0, im.size[0], im.size[1]))\n",
    "        return padded\n",
    "\n",
    "    def minmax_size(\n",
    "        self,\n",
    "        img: Image.Image,\n",
    "    ) -> Image.Image:\n",
    "        \"\"\"Resize or pad an image to fit into given dimensions\n",
    "\n",
    "        Args:\n",
    "            img (Image): Image to scale up/down.\n",
    "\n",
    "        Returns:\n",
    "            Image: Image with correct dimensionality\n",
    "        \"\"\"\n",
    "        if self.max_dims is not None:\n",
    "            ratios = [a / b for a, b in zip(img.size, self.max_dims)]\n",
    "            if any([r > 1 for r in ratios]):\n",
    "                size = np.array(img.size) // max(ratios)\n",
    "                size = np.maximum(size, 1)\n",
    "                img = img.resize(tuple(size.astype(int)), Image.BILINEAR)\n",
    "\n",
    "        if self.min_dims is not None:\n",
    "            padded_size: List[Union[int, int]] = [\n",
    "                max(img_dim, min_dim)\n",
    "                for img_dim, min_dim in zip(img.size, self.min_dims)\n",
    "            ]\n",
    "\n",
    "            new_pad_size = tuple(padded_size)\n",
    "            if new_pad_size != img.size:  # assert hypothesis\n",
    "                padded_im = Image.new(\"L\", new_pad_size, 255)\n",
    "                padded_im.paste(img, img.getbbox())\n",
    "                img = padded_im\n",
    "        return img\n",
    "\n",
    "    def normalize(self, img: np.ndarray, max_pixel_value=255.0) -> np.ndarray:\n",
    "        mean = self.mean * max_pixel_value\n",
    "        std = self.std * max_pixel_value\n",
    "        denominator = np.reciprocal(std, dtype=np.float32)\n",
    "        img = img.astype(np.float32)\n",
    "        img -= mean\n",
    "        img *= denominator\n",
    "        return img\n",
    "\n",
    "    @staticmethod\n",
    "    def to_gray(img) -> np.ndarray:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        return cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    @staticmethod\n",
    "    def transpose_and_four_dim(img: np.ndarray) -> np.ndarray:\n",
    "        return img.transpose(2, 0, 1)[:1][None, ...]\n",
    "\n",
    "        \n",
    "class TokenizerCls:\n",
    "    def __init__(self, json_file: Union[Path, str]):\n",
    "        self.tokenizer = Tokenizer(BPE()).from_file(str(json_file))\n",
    "    \n",
    "    def token2str(self, tokens) -> List[str]:\n",
    "        if len(tokens.shape) == 1:\n",
    "            tokens = tokens[None, :]\n",
    "    \n",
    "        dec = [self.tokenizer.decode(tok.tolist()) for tok in tokens]\n",
    "        return [\n",
    "            \"\".join(detok.split(\" \"))\n",
    "            .replace(\"Ġ\", \" \")\n",
    "            .replace(\"[EOS]\", \"\")\n",
    "            .replace(\"[BOS]\", \"\")\n",
    "            .replace(\"[PAD]\", \"\")\n",
    "            .strip()\n",
    "            for detok in dec\n",
    "        ]\n",
    "        \n",
    "class LaTeXOCR:\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_resizer_path: Union[str, Path] = None,\n",
    "        encoder_path: Union[str, Path] = None,\n",
    "        decoder_path: Union[str, Path] = None,\n",
    "        tokenizer_json: Union[str, Path] = None,\n",
    "    ):\n",
    "        self.image_resizer_path = image_resizer_path\n",
    "        self.encoder_path = encoder_path\n",
    "        self.decoder_path = decoder_path\n",
    "        self.tokenizer_json = tokenizer_json\n",
    "        \n",
    "        input_params = {\n",
    "    'max_width': 672, 'max_height': 192, 'min_height': 32, 'min_width': 32, 'bos_token': 1, 'max_seq_len': 512, 'eos_token': 2, 'temperature': 0.00001\n",
    "    }\n",
    "        self.max_dims = [input_params['max_width'], input_params['max_height']]\n",
    "        self.min_dims = [input_params['min_width'], input_params['min_height']]\n",
    "        self.temperature = input_params['temperature']\n",
    "\n",
    "        self.load_img = LoadImage()\n",
    "        self.pre_pro = PreProcess(max_dims=self.max_dims, min_dims=self.min_dims)\n",
    "        self.image_resizer = OrtInferSession(self.image_resizer_path)\n",
    "\n",
    "        self.encoder_decoder = EncoderDecoder(\n",
    "            encoder_path=self.encoder_path,\n",
    "            decoder_path=self.decoder_path,\n",
    "            bos_token=input_params['bos_token'],\n",
    "            eos_token=input_params['eos_token'],\n",
    "            max_seq_len=input_params['max_seq_len'],\n",
    "        )\n",
    "        self.tokenizer = TokenizerCls(self.tokenizer_json)\n",
    "\n",
    "    def __call__(self, img: InputType) -> Tuple[str, float]:\n",
    "        s = time.perf_counter()\n",
    "\n",
    "        try:\n",
    "            img = self.load_img(img)\n",
    "        except LoadImageError as exc:\n",
    "            error_info = traceback.format_exc()\n",
    "            raise LoadImageError(\n",
    "                f\"Load the img meets error. Error info is {error_info}\"\n",
    "            ) from exc\n",
    "\n",
    "        try:\n",
    "            resizered_img = self.loop_image_resizer(img)\n",
    "        except Exception as e:\n",
    "            error_info = traceback.format_exc()\n",
    "            raise ValueError(\n",
    "                f\"image resizer meets error. Error info is {error_info}\"\n",
    "            ) from e\n",
    "\n",
    "        try:\n",
    "            dec = self.encoder_decoder(resizered_img, temperature=self.temperature)\n",
    "        except Exception as e:\n",
    "            error_info = traceback.format_exc()\n",
    "            raise ValueError(\n",
    "                f\"EncoderDecoder meets error. Error info is {error_info}\"\n",
    "            ) from e\n",
    "\n",
    "        decode = self.tokenizer.token2str(dec)\n",
    "        pred = self.post_process(decode[0])\n",
    "\n",
    "        elapse = time.perf_counter() - s\n",
    "        return pred, elapse\n",
    "\n",
    "    def loop_image_resizer(self, img: np.ndarray) -> np.ndarray:\n",
    "        pillow_img = Image.fromarray(img)\n",
    "        pad_img = self.pre_pro.pad(pillow_img)\n",
    "        input_image = self.pre_pro.minmax_size(pad_img).convert(\"RGB\")\n",
    "        r, w, h = 1, input_image.size[0], input_image.size[1]\n",
    "        for _ in range(10):\n",
    "            h = int(h * r)\n",
    "            final_img, pad_img = self.pre_process(input_image, r, w, h)\n",
    "\n",
    "            resizer_res = self.image_resizer([final_img.astype(np.float32)])[0]\n",
    "\n",
    "            argmax_idx = int(np.argmax(resizer_res, axis=-1))\n",
    "            w = (argmax_idx + 1) * 32\n",
    "            if w == pad_img.size[0]:\n",
    "                break\n",
    "\n",
    "            r = w / pad_img.size[0]\n",
    "        return final_img\n",
    "\n",
    "    def pre_process(\n",
    "        self, input_image: Image.Image, r, w, h\n",
    "    ) -> Tuple[np.ndarray, Image.Image]:\n",
    "        if r > 1:\n",
    "            resize_func = Image.Resampling.BILINEAR\n",
    "        else:\n",
    "            resize_func = Image.Resampling.LANCZOS\n",
    "\n",
    "        resize_img = input_image.resize((w, h), resize_func)\n",
    "        pad_img = self.pre_pro.pad(self.pre_pro.minmax_size(resize_img))\n",
    "        cvt_img = np.array(pad_img.convert(\"RGB\"))\n",
    "\n",
    "        gray_img = self.pre_pro.to_gray(cvt_img)\n",
    "        normal_img = self.pre_pro.normalize(gray_img)\n",
    "        final_img = self.pre_pro.transpose_and_four_dim(normal_img)\n",
    "        return final_img, pad_img\n",
    "\n",
    "    @staticmethod\n",
    "    def post_process(s: str) -> str:\n",
    "        \"\"\"Remove unnecessary whitespace from LaTeX code.\n",
    "\n",
    "        Args:\n",
    "            s (str): Input string\n",
    "\n",
    "        Returns:\n",
    "            str: Processed image\n",
    "        \"\"\"\n",
    "        text_reg = r\"(\\\\(operatorname|mathrm|text|mathbf)\\s?\\*? {.*?})\"\n",
    "        letter = \"[a-zA-Z]\"\n",
    "        noletter = r\"[\\W_^\\d]\"\n",
    "        names = [x[0].replace(\" \", \"\") for x in re.findall(text_reg, s)]\n",
    "        s = re.sub(text_reg, lambda match: str(names.pop(0)), s)\n",
    "        news = s\n",
    "        while True:\n",
    "            s = news\n",
    "            news = re.sub(r\"(?!\\\\ )(%s)\\s+?(%s)\" % (noletter, noletter), r\"\\1\\2\", s)\n",
    "            news = re.sub(r\"(?!\\\\ )(%s)\\s+?(%s)\" % (noletter, letter), r\"\\1\\2\", news)\n",
    "            news = re.sub(r\"(%s)\\s+?(%s)\" % (letter, noletter), r\"\\1\\2\", news)\n",
    "            if news == s:\n",
    "                break\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdb3e80c-d344-4c15-a565-e7c3fd4d586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7905a1-e3a8-418a-ba27-f5b5615184de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.19.2-cp39-cp39-win_amd64.whl.metadata (4.7 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\xuema\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\xuema\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime) (5.29.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from onnxruntime) (1.13.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached onnxruntime-1.19.2-cp39-cp39-win_amd64.whl (11.1 MB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: pyreadline3, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.19.2 pyreadline3-3.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f805902-82ed-428c-8ce1-4b3e5b1e3ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5536ee59-8e4e-4321-93f9-08c2e22459fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8cb2ad-507e-4c64-aee3-b51b8849b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.13.4)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers\n",
      "Successfully installed fsspec-2024.10.0 huggingface-hub-0.27.0 tokenizers-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e08064c-34e8-449e-804f-eec46cecdcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuema\\OneDrive\\Desktop\\PortableApps\\math_ocr\\formulae\\test\\0000013.png\n",
      "<class 'bytes'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuema\\AppData\\Local\\Temp\\ipykernel_32816\\1293005924.py:522: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  argmax_idx = int(np.argmax(resizer_res, axis=-1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_{i j}(x)=\\frac{1}{a^{2}}\\,\\delta_{i j},\\;\\;\\phi^{a}(x)=\\phi^{a},\\;\\;\\;\\;(a,\\phi^{a};\\;\\mathrm{\\;const.})\n",
      "5.145268499999986\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "img_path = wd + '\\\\formulae\\\\test\\\\0000013.png'\n",
    "print(img_path)\n",
    "\n",
    "image_resizer_path = wd + '\\\\models\\\\image_resizer.onnx'\n",
    "encoder_path = wd + '\\\\models\\\\encoder.onnx'\n",
    "decoder_path = wd + '\\\\models\\\\decoder.onnx'\n",
    "tokenizer_json = wd + '\\\\models\\\\tokenizer.json'\n",
    "model = LaTeXOCR(image_resizer_path=image_resizer_path,\n",
    "                encoder_path=encoder_path,\n",
    "                decoder_path=decoder_path,\n",
    "                tokenizer_json=tokenizer_json)\n",
    "\n",
    "with open(img_path, 'rb') as f:\n",
    "    data = f.read()\n",
    "print(type(data))\n",
    "res, elapse = model(data)\n",
    "\n",
    "print(res)\n",
    "print(elapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db4f2fd7-a35e-479e-9cd3-147c3f3e760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\xuema\\appdata\\roaming\\python\\python39\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from flask) (3.1.3)\n",
      "Collecting itsdangerous>=2.2 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.9 (from flask)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from flask) (7.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=3.6->flask) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\xuema\\programs\\python\\python39\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.5)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: itsdangerous, click, blinker, flask\n",
      "Successfully installed blinker-1.9.0 click-8.1.7 flask-3.1.0 itsdangerous-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4062b5f8-a082-4050-9def-76f6b8cb1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir flask_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b4edf8-d578-4fe3-b621-4f5075d19ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1ef5b-850e-457d-98c4-3e9e419dfb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
